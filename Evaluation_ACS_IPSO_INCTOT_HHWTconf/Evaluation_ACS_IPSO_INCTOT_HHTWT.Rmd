---
title: ACS Dataset Evaluation Report - IPSO v2
subtitle: Use Case School testing
author: Steffen Moritz, Hariolf Merkle, Felix Geyer, Michel Reiffert, Reinhard Tent (DESTATIS)
date: January 28, 2022
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
    toc: true
    toc_depth: 1
# pdf_document:
#    toc: true
#    toc_depth: 1
---




```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
library("kableExtra")
```

```{r dataset, include=FALSE}
# Load Source Dataset
load(here::here("results/fg_ipso_regsdc_conf_from_INCTOT_HHWTconf.rda"))
load(here::here("Evaluation_ACS_IPSO_INCTOT_HHWTconf/results_acs_IPSO2_2.RData"))
#load(here::here("acs.RData"))
result <- results_acs_IPSO2
```
# Executive Summary


Based on our previous setup for the IPSO approach, we basically come to the same conclusion. Simulated data using the IPSO approach is not suitable way to generate synthetic data from the ACS dataset. The reader should also be aware, that only a part of this dataset is synthetic. Hence, a high utility for the original variables should not be surprising. The utility measures for the synthetic part are not supporting the usage. The S_pMSE for tables is usually high for the synthetic part. Also the absolute difference in densities and the Bhattacharyya are not supporting a high utility accordingly. Mlodak's information loss criterion underpinns the overall impression.




Based on the results of this document, we rate the suitability of this synthetic dataset for the use cases as follows:

**Releasing to public: NO ** 

**Testing analysis: NO **

**Education: YES **

**Testing technology: YES, but too elaborated **



# Dataset Considerations
When deciding, if data is released to the public it is of utmost importance to define, which variables are the most relevant in terms of privacy and utility. This domain and country specific, since different areas of the world have different privacy legislation and feature specific overall circumstances. This step would require input and discussions with actual domain experts. Since we are foreign to US privacy law, the assumptions made for the Synthetic Data Challenge are basically an educated guess from our side.
From a utility perspective it is important to know which variables and correlations are most interesting for actual users of the created synthetic dataset. Different use cases might require focus on different variables and correlations. We could not single out a most important variable, thus in our utility analysis we decided to focus on the overall utility and not to prioritize a specific variable.
We decided to remove the first column of the ACS dataset, since it only contains column numbers and hence doesn’t need to be altered by any means.
From a privacy perspective it has to be decided, which variables are confidential and which are identifying. As already mentioned, specifying this depends on multiple factors e.g. regulations or also other public information, that could be used for de-anonymization. For our analysis, we made the following assumptions: Of course any information about income has to be considered as confidential, otherwise publishing income statistics would be a way easier task for NSOs than it actually is. So INCTOT, INCWAGE, INCWELFR, INCINVST, INCEARN and POVERTY are treated as confidential variables. Additionally the times a person is not at home also is an information that encroaches in personal right and might be to the respondents detriment e.g. by burglars. The features HHWT and PERWT are weights that only present information about the way the dataset was created and hence are neither confidential nor identifying. All the other information (like Sex, Age, Race…) contain observable information and hence, in our opinion, are identifying variables.

# Method Considerations
Similar to the FCS-method, IPSO is easy to understand and to explain, since it is based on classic linear regression. For applying IPSO, we chose the R package RegSDC that provides a framework containing several versions of the method. We applied the classical version of IPSO provided by the function RegSDCipso.

IPSO requires to split up the variables in non-confidential ones and confidential ones. It assumes statistical independence among the non-confidential variables and multivariate normally distributed confidential variables. The assumption is strong and holds in general not for the ACS dataset, therefore poor quality of the synthetical data is inevitable. We classified the sat-related variables and sex as non-confidential and the gpa-related variables as confidential. 

The computation time for IPSO was superb. Since the basic assumptions of IPSO are not fulfilled in the ACS data set, we have dispensed with parameter tuning.



# Utility Evaluation

Different utility measures are applied in this section. These utility measures are the basis of utility evaluation for the generated synthetic dataset. The R packages synthpop, sdcMicro and corrplot were used to compute the following metrics. We do not use tests incorporating significance here. Confidence intervals in large surveys often tend to be extremely small so many slight differences appear to be significant. We do not consider the variable PUMA for our utility evaluation. During the ACS reports, some minor changes in availability regarding plots might occur. This is caused by the application of standardised scripts on different synthetic datasets.

### Graphical Comparison for Margins (R-Package: synthpop)

The following histograms provide an ad-hoc overview on the marginal distributions of the original and synthetic dataset. Matching or close distributions are related to a high data utility.

```{r, echo = FALSE, warning=FALSE, message=FALSE, fig.show= TRUE, results = 'hide'}
result$comp1$plots
result$comp2$plots
result$comp3$plots
result$comp4$plots
result$comp5$plots

```





### Correlation Plots for Graphical Comparison of Pearson Correlation 

Synthetic Datasets should represent the dependencies of the original datasets. The following correlation plots provide an ad-hoc overview on the Pearson correlations of the original and synthetic dataset. The left plot shows the original correlation whereas the right plot provides the correlation based on the synthetic dataset.




```{r, echo = FALSE, warning=FALSE, message=FALSE}
library("corrplot")
par(mfrow=c(1,2))
corrplot(results_acs_IPSO2$cp1_1$corr, method = "color", type = "lower")
corrplot(results_acs_IPSO2$cp2_1$corr, method = "color", type = "lower")
```





### Distributional Comparison of Synthesised Data (R-Package: synthpop) by (S_)pMSE

Propensity scores are calculated on a combined dataset (original and synthetic). A model (here: CART) tries to identify the synthetic units in the dataset. Since both datasets should be identically structured, the pMSE should equal zero. The S_pMSE (standardised pMSE) should not exceed 10 and for a good fit below 3 according to Raab (2021, https://unece.org/sites/default/files/2021-12/SDC2021_Day2_Raab_AD.pdf)

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- result$comp1$tab.utility
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- data.frame(pMSE = result$ug1$pMSE, S_pMSE = result$ug1$S_pMSE)
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- result$comp2$tab.utility
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- data.frame(pMSE = result$ug2$pMSE, S_pMSE = result$ug2$S_pMSE)
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- result$comp3$tab.utility
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- data.frame(pMSE = result$ug3$pMSE, S_pMSE = result$ug3$S_pMSE)
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- result$comp4$tab.utility
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- data.frame(pMSE = result$ug4$pMSE, S_pMSE = result$ug4$S_pMSE)
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- result$comp5$tab.utility
kbl(ug1) %>%
  kable_paper(full_width = F) 
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
ug1 <- data.frame(pMSE = result$ug5$pMSE, S_pMSE = result$ug5$S_pMSE)
kbl(ug1) %>%
  kable_paper(full_width = F) 
```



### Two-way Tables Comparison of Synthesised Data (R-Package: synthpop) by (S_)pMSE

Two-way tables are evaluated based on the original and the synthetic dataset based on S_pMSE (see above). We also present the results for the mean absolute difference in densities (MabsDD) and the Bhattacharyya distance (dBhatt).



```{r, echo = FALSE, warning=FALSE, message=FALSE}


#result$ut$utility.plot

result$ut1_1$utility.plot
result$ut1_2$utility.plot
result$ut1_3$utility.plot
result$ut1_4$utility.plot
result$ut1_5$utility.plot

```


```{r, echo = FALSE, warning=FALSE, message=FALSE}


#result$ut$utility.plot

result$ut2_1$utility.plot
result$ut2_2$utility.plot
result$ut2_3$utility.plot
result$ut2_4$utility.plot
result$ut2_5$utility.plot

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}


#result$ut$utility.plot

result$ut3_1$utility.plot
result$ut3_2$utility.plot
result$ut3_3$utility.plot
result$ut3_4$utility.plot
result$ut3_5$utility.plot

```




### Information Loss Measure Proposed by Andrzej Mlodak (R-Package: sdcMicro)

The value of this information loss criterion is between 0 (no information loss) and 1. It is calculated overall and for each variable.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

result$il

```


# Tuning and Optimizations
