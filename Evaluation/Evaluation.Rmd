---
title: SAT Dataset Evaluation Report - Method FCS
subtitle: Use Case School testing
author: Steffen Moritz, Hariolf Merkle, Felix Geyer, Michel Reiffert, Reinhard Tent (DESTATIS)
date: January 28, 2022
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
    toc: true
# pdf_document:
#    toc: true
#    toc_depth: 1
---




```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
```

```{r dataset, include=FALSE}
# Load Source Dataset
load(here::here("results/sm_sat_gan_ctgan_epoch1000.rda"))
load(here::here("satgpa.rda"))
original <- as.data.frame(satgpa)
synthetic <- as.data.frame(result_gan)
```
# Executive Summary
According to our results FCS is only partially usefule for the use case xyz with the SAT data. In comparison to methods xza and yzt it lacks utility. Scores for our main metric was xxx compared to xxx. Also for risk it seems like it is not a good idea. As the use case reuqires to have xxx and xxx and also provides full data to . An advantage of the method we see is the easy way to apply and processing speed for huge datasets.


The method you used
Whether or not you used any specific tooling to generate your synthetic data

How you evaluated your data (specify any specific measures and their results).

Created both a fully synthetic and a partially synthetic file
Evidence of tuning

# Dataset and Use Case considerations
Challenges we faced with the SAT datset were ... it was important for us to keep ... sum ..
For privacy we argued that ...

# Method considerations
Overall full ... seems to be a good choice for ... 

# Privacy and Risk Evaluation

Lorem ipsum hjdgs adsa this is good this is bad that is why sfd Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t

```{r privacy metrics, echo=FALSE, warning = FALSE, message= FALSE}
library(synthpop)
library(dplyr)

generate_uniques_for_sat <-function(df_orig, df_synth, exclude = NULL){
  syn_synth <- list(m = 1, syn = df_synth)
  replicated.uniques(object = syn_synth, data = df_orig , exclude = exclude)
}

generate_uniques_pp_for_sat <-function(df_orig, df_synth,identifiers = 1:4 ,  p = 0.05){
  syn_synth <- list(m = 1, syn = df_synth[,identifiers])
  syn_orig <- list(m = 1, syn = df_orig[,identifiers])
  
  repl_synth <- replicated.uniques(object = syn_synth, data = df_orig[,identifiers])$replications
  repl_orig <- replicated.uniques(object = syn_orig, data = df_synth[,identifiers])$replications
  

  df <- inner_join(df_synth[repl_synth,], df_orig[repl_orig,], 
                   by=names(df_orig)[identifiers], 
                   suffix = c("_synth", "_orig"))
  
  count_disclosure <- df %>%
    mutate(hs_gpa_diff = abs(hs_gpa_synth-hs_gpa_orig)/abs(hs_gpa_orig), 
           fy_gpa_diff = abs(fy_gpa_synth-fy_gpa_orig)/abs(fy_gpa_orig) ) %>%
    filter(hs_gpa_diff < p | fy_gpa_diff < p)%>%
    count(.)
  result = list(replications_synth = sum(repl_synth),replications_orig = sum(repl_orig),
                count_disclosure = count_disclosure[1,1], per_replications = 100*count_disclosure[1,1]/nrow(df_synth))
}


synthetic$hs_gpa <- round(synthetic$hs_gpa,2)
synthetic$fy_gpa <- round(synthetic$fy_gpa,2)

# Disclosure Risk  - selbstentwickelt
disclosure_own <- generate_uniques_pp_for_sat(original, synthetic)



# Data Frame Own Metric
pp <- data.frame(`Replications Orig.` = disclosure_own$replications_orig, `Replications Synth.` = disclosure_own$replications_synth, `Count Disclosure` = disclosure_own$count_disclosure, `Percentage Disclosure` = disclosure_own$per_replications)




library("kableExtra")



kbl(pp) %>%
  kable_paper(full_width = F) 



```

Lorem ipsum hjdgs adsa this is good this is bad that is why sfd Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t Lorem ipsum hjdgs adsa t


```{r, echo=FALSE, warning = FALSE, message= FALSE}
# Disclosure Risk
disclosure <- generate_uniques_for_sat(original, synthetic)

# Perceived disclosure risk
disclosure_percei <- generate_uniques_for_sat(original, synthetic, exclude = c("hs_gpa", "fy_gpa") )


pp2 <- data.frame(`Metric` = c("Perceived Risk", "Actual Risk"), 
                 `Number Uniques` = c(disclosure_percei$no.uniques, disclosure$no.uniques), 
                 `Number Replications` = c(disclosure_percei$no.replications,disclosure$no.replications ),  
                 `Percentage Replications` = c(disclosure_percei$per.replications, disclosure$per.replications)
                 )

kbl(pp2) %>%
  kable_paper(full_width = F) 
```



# Utility Evaluation

par(mfrow = c(1,2))
mean(results_sm_sat_gan_ctgan_epoch1000$ks > 0.05)
results_sm_sat_gan_ctgan_epoch1000$comp
results_sm_sat_gan_ctgan_epoch1000$il
corrplot(results_sm_sat_gan_ctgan_epoch1000$cp1$corr, method = "color", type = "lower", main = "Original")
corrplot(results_sm_sat_gan_ctgan_epoch1000$cp2$corr, method = "color", type = "lower", main = "Synthetic")
results_sm_sat_gan_ctgan_epoch1000$ug
results_sm_sat_gan_ctgan_epoch1000$ut


# Tuning and Optimizations